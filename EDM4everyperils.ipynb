{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "1 ) First Create a BLANK EDM in RISK LINK and import a sample MRI file according to the peril\n",
    "2) Give the name of sample EDM in datbase ( tHIS  L)\n",
    "3)Run the script\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file using Polars\n",
    "df = pl.read_csv(\"input\\THEQ_SAMPLE_6.csv\", separator='\\t') # give the location file path here\n",
    "perilno=int(input(\" Enter the peril number you are going to run \"))\n",
    "currency=\"USD\"\n",
    "undate = \"9999-12-31 00:00:00\"\n",
    "Idate = \"12/3/2024 12:00:00 AM\"\n",
    "Edate = \"12/2/2025 12:00:00 AM\"\n",
    "sample_database_name = input (\"enter the name of sample database\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_to_unpivot(perilno):\n",
    "    if perilno == 1:\n",
    "        return [\"EQCV1VAL\", \"EQCV2VAL\", \"EQCV3VAL\"]\n",
    "    elif perilno == 2:\n",
    "        return [\"WSCV1VAL\", \"WSCV2VAL\", \"WSCV3VAL\"]    \n",
    "    elif perilno == 3:\n",
    "        return [\"TOCV1VAL\", \"TOCV2VAL\", \"TOCV3VAL\"]\n",
    "    elif perilno==4:\n",
    "        return [\"FLCV1VAL\", \"FLCV2VAL\", \"FLCV3VAL\"]\n",
    "    elif perilno==5:\n",
    "        return[\"FRCV1VAL\", \"FRCV2VAL\", \"FRCV3VAL\"]\n",
    "    elif perilno==6:\n",
    "        return[\"TRCV1VAL\", \"TRCV2VAL\", \"TRCV3VAL\"]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported perilno value\")\n",
    "\n",
    "\n",
    "\n",
    "# Get columns to unpivot based on perilno\n",
    "columns_to_unpivot = get_columns_to_unpivot(perilno)\n",
    "\n",
    "# Define id_vars\n",
    "id_vars = [col for col in df.columns if col not in columns_to_unpivot]\n",
    "\n",
    "# Unpivot the DataFrame\n",
    "unpivoted_df = df.unpivot(\n",
    "    index=id_vars,\n",
    "    on=columns_to_unpivot,\n",
    "    variable_name=\"losstype\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Map losstype to corresponding values\n",
    "columns_to_unpivot_mapping = {\n",
    "    \"EQCV1VAL\": 1,\n",
    "    \"EQCV2VAL\": 2,\n",
    "    \"EQCV3VAL\": 3,\n",
    "    \"WSCV1VAL\": 1,\n",
    "    \"WSCV2VAL\": 2,\n",
    "    \"WSCV3VAL\": 3,\n",
    "    \"TOCV1VAL\": 1,\n",
    "    \"TOCV2VAL\": 2,\n",
    "    \"TOCV3VAL\": 3,\n",
    "    \"FLCV1VAL\": 1,\n",
    "    \"FLCV2VAL\": 2,\n",
    "    \"FLCV3VAL\": 3,\n",
    "    \"FRCV1VAL\": 1,\n",
    "    \"FRCV2VAL\": 2,\n",
    "    \"FRCV3VAL\": 3,\n",
    "    \"TRCV1VAL\": 1,\n",
    "    \"TRCV2VAL\": 2,\n",
    "    \"TRCV3VAL\": 3\n",
    "}\n",
    "\n",
    "unpivoted_df = unpivoted_df.with_columns([\n",
    "    pl.col(\"losstype\").map_elements(lambda x: columns_to_unpivot_mapping.get(x, None), return_dtype=pl.Int32).alias(\"losstype\")\n",
    "])\n",
    "\n",
    "# Add COVGMODE column\n",
    "unpivoted_df = unpivoted_df.with_columns([\n",
    "    pl.when(pl.col(\"losstype\") == 2).then(3).otherwise(0).alias(\"COVGMODE\")\n",
    "])\n",
    "\n",
    "# Define the mapping from losstype to labelid\n",
    "losstype_to_labelid = {\n",
    "    1: 7,\n",
    "    2: 8,\n",
    "    3: 9\n",
    "}\n",
    "\n",
    "# Add the labelid column based on the losstype column\n",
    "unpivoted_df = unpivoted_df.with_columns([\n",
    "    pl.col(\"losstype\").map_elements(lambda x: losstype_to_labelid.get(x, None), return_dtype=pl.Int32).alias(\"labelid\")\n",
    "])\n",
    "\n",
    "# Sort the DataFrame by LOCNUM\n",
    "unpivoted_df = unpivoted_df.sort(\"LOCNUM\")\n",
    "\n",
    "# Add the LOCCVGID column\n",
    "unpivoted_df = unpivoted_df.with_columns([\n",
    "    pl.arange(1, unpivoted_df.height + 1).alias(\"LOCCVGID\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (18, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Geoid</th><th>LONGITUDE</th><th>LATITUDE</th><th>LOCNUM</th><th>LOCNAME</th><th>ACCNTNUM</th><th>CNTRYCODE</th><th>CNTRYSCHEME</th><th>BLDGSCHEME</th><th>BLDGCLASS</th><th>OCCSCHEME</th><th>OCCTYPE</th><th>NUMBLDGS</th><th>NUMSTORIES</th><th>losstype</th><th>Value</th><th>COVGMODE</th><th>labelid</th><th>LOCCVGID</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i32</td><td>i64</td><td>i32</td><td>i32</td><td>i64</td></tr></thead><tbody><tr><td>1970864</td><td>97.65</td><td>8.45</td><td>4</td><td>4</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1000000</td><td>0</td><td>7</td><td>1</td></tr><tr><td>1970864</td><td>97.65</td><td>8.45</td><td>4</td><td>4</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>2</td><td>500000</td><td>3</td><td>8</td><td>2</td></tr><tr><td>1970864</td><td>97.65</td><td>8.45</td><td>4</td><td>4</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>3</td><td>250000</td><td>0</td><td>9</td><td>3</td></tr><tr><td>1970865</td><td>97.65</td><td>8.55</td><td>5</td><td>5</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1000000</td><td>0</td><td>7</td><td>4</td></tr><tr><td>1970865</td><td>97.65</td><td>8.55</td><td>5</td><td>5</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>2</td><td>500000</td><td>3</td><td>8</td><td>5</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1970984</td><td>97.85</td><td>9.45</td><td>8</td><td>8</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>2</td><td>500000</td><td>3</td><td>8</td><td>14</td></tr><tr><td>1970984</td><td>97.85</td><td>9.45</td><td>8</td><td>8</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>3</td><td>250000</td><td>0</td><td>9</td><td>15</td></tr><tr><td>1970994</td><td>97.95</td><td>9.45</td><td>9</td><td>9</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1000000</td><td>0</td><td>7</td><td>16</td></tr><tr><td>1970994</td><td>97.95</td><td>9.45</td><td>9</td><td>9</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>2</td><td>500000</td><td>3</td><td>8</td><td>17</td></tr><tr><td>1970994</td><td>97.95</td><td>9.45</td><td>9</td><td>9</td><td>&quot;THEQ&quot;</td><td>&quot;TH&quot;</td><td>&quot;ISO2A&quot;</td><td>&quot;RMS&quot;</td><td>0</td><td>&quot;ATC&quot;</td><td>0</td><td>1</td><td>0</td><td>3</td><td>250000</td><td>0</td><td>9</td><td>18</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (18, 19)\n",
       "┌─────────┬───────────┬──────────┬────────┬───┬─────────┬──────────┬─────────┬──────────┐\n",
       "│ Geoid   ┆ LONGITUDE ┆ LATITUDE ┆ LOCNUM ┆ … ┆ Value   ┆ COVGMODE ┆ labelid ┆ LOCCVGID │\n",
       "│ ---     ┆ ---       ┆ ---      ┆ ---    ┆   ┆ ---     ┆ ---      ┆ ---     ┆ ---      │\n",
       "│ i64     ┆ f64       ┆ f64      ┆ i64    ┆   ┆ i64     ┆ i32      ┆ i32     ┆ i64      │\n",
       "╞═════════╪═══════════╪══════════╪════════╪═══╪═════════╪══════════╪═════════╪══════════╡\n",
       "│ 1970864 ┆ 97.65     ┆ 8.45     ┆ 4      ┆ … ┆ 1000000 ┆ 0        ┆ 7       ┆ 1        │\n",
       "│ 1970864 ┆ 97.65     ┆ 8.45     ┆ 4      ┆ … ┆ 500000  ┆ 3        ┆ 8       ┆ 2        │\n",
       "│ 1970864 ┆ 97.65     ┆ 8.45     ┆ 4      ┆ … ┆ 250000  ┆ 0        ┆ 9       ┆ 3        │\n",
       "│ 1970865 ┆ 97.65     ┆ 8.55     ┆ 5      ┆ … ┆ 1000000 ┆ 0        ┆ 7       ┆ 4        │\n",
       "│ 1970865 ┆ 97.65     ┆ 8.55     ┆ 5      ┆ … ┆ 500000  ┆ 3        ┆ 8       ┆ 5        │\n",
       "│ …       ┆ …         ┆ …        ┆ …      ┆ … ┆ …       ┆ …        ┆ …       ┆ …        │\n",
       "│ 1970984 ┆ 97.85     ┆ 9.45     ┆ 8      ┆ … ┆ 500000  ┆ 3        ┆ 8       ┆ 14       │\n",
       "│ 1970984 ┆ 97.85     ┆ 9.45     ┆ 8      ┆ … ┆ 250000  ┆ 0        ┆ 9       ┆ 15       │\n",
       "│ 1970994 ┆ 97.95     ┆ 9.45     ┆ 9      ┆ … ┆ 1000000 ┆ 0        ┆ 7       ┆ 16       │\n",
       "│ 1970994 ┆ 97.95     ┆ 9.45     ┆ 9      ┆ … ┆ 500000  ┆ 3        ┆ 8       ┆ 17       │\n",
       "│ 1970994 ┆ 97.95     ┆ 9.45     ┆ 9      ┆ … ┆ 250000  ┆ 0        ┆ 9       ┆ 18       │\n",
       "└─────────┴───────────┴──────────┴────────┴───┴─────────┴──────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Global list to store newly created database names\n",
    "new_databases = []\n",
    "\n",
    "# Function to execute a SQL command using sqlcmd\n",
    "def execute_sql_command(server, sql_query):\n",
    "    try:\n",
    "        subprocess.run(f\"sqlcmd -S {server} -Q \\\"{sql_query}\\\"\", check=True, shell=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"SQL command failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to drop a database if it exists and has a specific extension\n",
    "def drop_database_if_exists(server, database_name):\n",
    "    try:\n",
    "        if \"_\" in database_name:\n",
    "            drop_query = f\"IF EXISTS (SELECT name FROM sys.databases WHERE name = '{database_name}') DROP DATABASE [{database_name}]\"\n",
    "            execute_sql_command(server, drop_query)\n",
    "            print(f\"Database '{database_name}' dropped successfully if it existed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error dropping database {database_name}: {e}\")\n",
    "\n",
    "# Function to copy a database\n",
    "def copy_database(server, original_database_name, new_database_name, split_number):\n",
    "    \"\"\"\n",
    "    Copies a database on the specified SQL Server instance by performing a backup and restore operation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Copying database: {original_database_name} to {new_database_name}\")\n",
    "\n",
    "        # Drop the new database if it already exists and has an extension\n",
    "        drop_database_if_exists(server, new_database_name)\n",
    "\n",
    "        # Define paths for backup and new database files\n",
    "        backup_file = f\"D:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQLSERVER\\\\MSSQL13.MSSQLSERVER\\\\MSSQL\\\\Backup\\\\{original_database_name}_{split_number}.bak\"\n",
    "        data_file = f\"D:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQLSERVER\\MSSQL13.MSSQLSERVER\\MSSQL\\\\DATA{new_database_name}.mdf\"\n",
    "        log_file = f\"D:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQLSERVER\\MSSQL13.MSSQLSERVER\\MSSQL\\\\DATA{new_database_name}_log.ldf\"\n",
    "\n",
    "        # Backup the original database\n",
    "        backup_query = f\"BACKUP DATABASE [{original_database_name}] TO DISK = '{backup_file}'\"\n",
    "        execute_sql_command(server, backup_query)\n",
    "\n",
    "        # Restore the database with a new name\n",
    "        restore_query = (\n",
    "            f\"RESTORE DATABASE [{new_database_name}] FROM DISK = '{backup_file}' \"\n",
    "            f\"WITH MOVE '{original_database_name}' TO '{data_file}', \"\n",
    "            f\"MOVE '{original_database_name}_log' TO '{log_file}'\"\n",
    "        )\n",
    "        execute_sql_command(server, restore_query)\n",
    "\n",
    "        print(f\"Database '{new_database_name}' created successfully.\")\n",
    "        new_databases.append(new_database_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during database copy operation:\", e)\n",
    "        \n",
    "# Function to count rows in the DataFrame\n",
    "def count_rows_in_dataframe(df):\n",
    "    return len(df)\n",
    "\n",
    "# Function to split and create databases\n",
    "def split_and_create_databases(df, server, original_database_name, locations_per_split):\n",
    "    \"\"\"\n",
    "    Creates multiple database copies based on the number of rows in the DataFrame and the user-defined split size.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_rows = count_rows_in_dataframe(df)\n",
    "        print(f\"Total rows in the dataset: {total_rows}\")\n",
    "\n",
    "        # Determine the number of splits required\n",
    "        num_splits = (total_rows + locations_per_split - 1) // locations_per_split\n",
    "        print(f\"Number of splits required: {num_splits}\")\n",
    "\n",
    "        # Create the necessary database copies\n",
    "        for i in range(1, num_splits + 1):\n",
    "            new_database_name = f\"{original_database_name}_{i}\"\n",
    "            copy_database(server, original_database_name, new_database_name, i)\n",
    "\n",
    "        return new_databases\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while splitting and creating databases:\", e)\n",
    "        return []\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # User inputs and initial setup\n",
    "    try:\n",
    "        server = \"localhost\"\n",
    "        database_name = sample_datbase_name\n",
    "        locations_per_split = int(input(\"Enter the number of locations wanted in one split: \"))\n",
    "        # Create database copies\n",
    "        created_databases = split_and_create_databases(df, server, database_name, locations_per_split)\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Created Databases:\", created_databases)\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter numeric values for the split size.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding old codes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import polars as pl\n",
    "\n",
    "# Class to manage SQL connection\n",
    "class SQLConnection:\n",
    "    def __init__(self, server, database):\n",
    "        self.server = server\n",
    "        self.database = database\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def open(self):\n",
    "        # Open a persistent connection\n",
    "        self.connection = pyodbc.connect(\n",
    "            f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "            f\"SERVER={self.server};\"\n",
    "            f\"DATABASE={self.database};\"\n",
    "            \"Trusted_Connection=yes;\"\n",
    "        )\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "    def execute(self, sql_command):\n",
    "        try:\n",
    "            #print(f\"Executing SQL Command: {sql_command}\")\n",
    "            self.cursor.execute(sql_command)\n",
    "            self.connection.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command: {sql_command}\\nException: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.cursor:\n",
    "            self.cursor.close()\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "\n",
    "# Function to get table columns\n",
    "def get_table_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get foreign key columns\n",
    "def get_foreign_key_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"\"\"\n",
    "        SELECT COLUMN_NAME \n",
    "        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE \n",
    "        WHERE TABLE_NAME = '{table_name}' AND CONSTRAINT_NAME IN (\n",
    "            SELECT CONSTRAINT_NAME \n",
    "            FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching foreign key columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Server details\n",
    "server = \"localhost\"\n",
    "\n",
    "# Define table mappings (DataFrame column to database table columns)\n",
    "table_mappings = {\n",
    "    \"Address\": {\n",
    "        \"CountryScheme\": \"CNTRYSCHEME\", \"CountryCode\": \"CNTRYCODE\",\n",
    "        \"CountryRMSCode\": \"CNTRYCODE\", \"Latitude\": \"LATITUDE\", \"Longitude\": \"LONGITUDE\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define behavior for unspecified columns\n",
    "unspecified_column_behavior = {\n",
    "    \"Address\": {\n",
    "        \"default\": \"' '\",  # Default value for unspecified columns\n",
    "        \"null_columns\": ['ParcelNumber', 'Zone3', 'GeoProductVersion', 'GeoDateTime'],\n",
    "        \"blank_columns\": [],\n",
    "        \"zero_columns\": ['AddressTypeID', 'CountryGeoID', 'Admin1GeoID', 'Admin2GeoID', 'Admin3GeoID', 'CityGeoID', 'PostalCodeGeoID', 'AreaID', 'Zone1GeoID', 'GeoResolutionCode', 'GeoResolutionConfidence', 'GeoAccuracyBuffer', 'GeoDataSourceID', 'GeoDataSourceVersionID', 'Admin4GeoID', 'Admin5GeoID', 'LocationCodeGeoID', 'Zone2GeoID', 'Zone3GeoID', 'Zone4GeoID', 'Zone5GeoID']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Counter for AddressID\n",
    "address_id_counter = 4\n",
    "\n",
    "# Assume df and created_databases are defined elsewhere\n",
    "# Split the DataFrame into chunks\n",
    "chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "# Open the SQL connection once\n",
    "sql_conn = SQLConnection(server, created_databases[0])\n",
    "sql_conn.open()\n",
    "\n",
    "# Populate each chunk into the corresponding database\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i < len(created_databases):\n",
    "        database = created_databases[i]\n",
    "        print(f\"Populating database: {database}\")\n",
    "\n",
    "        # Switch database if necessary\n",
    "        if sql_conn.database != database:\n",
    "            sql_conn.close()\n",
    "            sql_conn = SQLConnection(server, database)\n",
    "            sql_conn.open()\n",
    "\n",
    "        # Delete existing rows from the Address table\n",
    "        sql_conn.execute(\"DELETE FROM Address\")\n",
    "        print(f\"All rows deleted from Address table in database {database}.\")\n",
    "\n",
    "        for row in chunk.iter_rows(named=True):\n",
    "            for table_name, column_mapping in table_mappings.items():\n",
    "                all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                mapped_columns = []\n",
    "                mapped_values = []\n",
    "\n",
    "                # Add mapped columns from the DataFrame\n",
    "                for table_col in all_columns:\n",
    "                    if table_col == 'AddressID':\n",
    "                        mapped_columns.append(table_col)\n",
    "                        mapped_values.append(f\"{address_id_counter}\")\n",
    "                    elif table_col in column_mapping:\n",
    "                        df_col = column_mapping[table_col]\n",
    "                        if df_col in row:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                    elif table_col not in foreign_key_columns:\n",
    "                        default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"' '\"})\n",
    "                        null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                        blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                        zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "\n",
    "                        if table_col in null_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"NULL\")\n",
    "                        elif table_col in blank_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"' '\")\n",
    "                        elif table_col in zero_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"0\")\n",
    "                        else:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                # Increment the AddressID counter\n",
    "                if 'AddressID' in mapped_columns:\n",
    "                    address_id_counter += 1\n",
    "\n",
    "                # Ensure the number of columns matches the number of values\n",
    "                if len(mapped_columns) == len(mapped_values):\n",
    "                    sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                    sql_conn.execute(sql_command)\n",
    "                else:\n",
    "                    print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "# Close the SQL connection after everything is completed\n",
    "sql_conn.close()\n",
    "\n",
    "print(\"Data population completed in Address table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [f\"_{i}\" for i in range(1, 96)]\n",
    "print(names)\n",
    "created_databases=names\n",
    "locations_per_split=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import polars as pl\n",
    "\n",
    "# Class to manage SQL connection\n",
    "class SQLConnection:\n",
    "    def __init__(self, server, database):\n",
    "        self.server = server\n",
    "        self.database = database\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def open(self):\n",
    "        # Open a persistent connection\n",
    "        self.connection = pyodbc.connect(\n",
    "            f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "            f\"SERVER={self.server};\"\n",
    "            f\"DATABASE={self.database};\"\n",
    "            \"Trusted_Connection=yes;\"\n",
    "        )\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "    def execute(self, sql_command):\n",
    "        try:\n",
    "            #print(f\"Executing SQL Command: {sql_command}\")\n",
    "            self.cursor.execute(sql_command)\n",
    "            self.connection.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command: {sql_command}\\nException: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.cursor:\n",
    "            self.cursor.close()\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "\n",
    "# Function to get table columns\n",
    "def get_table_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get foreign key columns\n",
    "def get_foreign_key_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"\"\"\n",
    "        SELECT COLUMN_NAME \n",
    "        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE \n",
    "        WHERE TABLE_NAME = '{table_name}' AND CONSTRAINT_NAME IN (\n",
    "            SELECT CONSTRAINT_NAME \n",
    "            FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching foreign key columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Server details\n",
    "server = \"localhost\"\n",
    "\n",
    "table_mappings = {\n",
    "    \"property\": {\"LOCNUM\":\"LOCNUM\",\"LOCNAME\":\"LOCNUM\",\n",
    "                 \"BLDGSCHEME\":\"BLDGSCHEME\",\"OCCSCHEME\":\"OCCSCHEME\",\"BLDGSCHEME\" :\"BLDGSCHEME\",\n",
    "                 \"OCCTYPE\":\"OCCTYPE\",\n",
    "                 \"OCCTYPE\":\"OCCTYPE\",\"NUMBLDGS\":\"NUMBLDGS\",\"NUMSTORIES\":\"NUMSTORIES\"},\n",
    "    \n",
    "}\n",
    "\n",
    "# Define behavior for unspecified columns\n",
    "unspecified_column_behavior = {\n",
    "    \"property\": {\n",
    "        \"default\": \"0\",  # General default value for unspecified columns\n",
    "        \"null_columns\": [],  # Columns where value should be NULL\n",
    "        \"blank_columns\": ['USERID1', 'USERID2', 'USERTXT1', 'USERTXT2', 'SITENAME', 'FLOOROCCUPANCY','HUZONE'],  # Columns where value should be a blank space\n",
    "        \"zero_columns\": [],  # Columns where value should be 0\n",
    "        \"specific_defaults\": {  # Columns with specific default values\n",
    "            \"YEARBUILT\": undate,\n",
    "            \"INCEPTDATE\": Idate,\n",
    "            \"EXPIREDATE\": Edate,\n",
    "            \"FLOODDEFENSEELEVATION\": \"-999\",\n",
    "            \"AREAUNIT\": \"2\",\n",
    "            \"HEIGHTUNIT\": \"2\",\n",
    "            \"PRIMARYBLDG\": \"1\",\n",
    "            \"FLOODDEFENSEELEVATIONUNIT\": \"2\",\n",
    "            \"FLOODDEFHTABOVEGRND\": \"-999\",\n",
    "            \"USERGROUNDELEV\": \"-999\",\n",
    "            \"USERBFE\": \"-999\",\n",
    "            \"CREATEDATETIME\": undate,\n",
    "            \"UPDATEDATETIME\": undate,\n",
    "            \"ACCGRPID\": \"1\",\n",
    "            'OTHERZONE':currency,\n",
    "            \n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "address_id_counter = 4\n",
    "loc_id_counter = 4  # Initialize LOCID counter\n",
    "primary_id_counter = 4  # Initialize PRIMARYLOCID counter\n",
    "\n",
    "# Assume df and created_databases are defined elsewhere\n",
    "# Split the DataFrame into chunks\n",
    "chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "# Open the SQL connection once\n",
    "sql_conn = SQLConnection(server, created_databases[0])\n",
    "sql_conn.open()\n",
    "\n",
    "# Populate each chunk into the corresponding database\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i < len(created_databases):\n",
    "        database = created_databases[i]\n",
    "        print(f\"Populating database: {database}\")\n",
    "\n",
    "        # Switch database if necessary\n",
    "        if sql_conn.database != database:\n",
    "            sql_conn.close()\n",
    "            sql_conn = SQLConnection(server, database)\n",
    "            sql_conn.open()\n",
    "\n",
    "        # Delete existing rows from the Property table\n",
    "        sql_conn.execute(\"DELETE FROM Property \")\n",
    "        print(f\"All rows deleted from Property table in database {database}.\")\n",
    "\n",
    "        for row in chunk.iter_rows(named=True):\n",
    "            for table_name, column_mapping in table_mappings.items():\n",
    "                all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                mapped_columns = []\n",
    "                mapped_values = []\n",
    "\n",
    "                # Add mapped columns from the DataFrame\n",
    "                for table_col in all_columns:\n",
    "                    if table_col == 'AddressID':\n",
    "                        mapped_columns.append(table_col)\n",
    "                        mapped_values.append(f\"{address_id_counter}\")\n",
    "                    elif table_col == 'LOCID':\n",
    "                        mapped_columns.append(table_col)\n",
    "                        mapped_values.append(f\"{loc_id_counter}\")\n",
    "                    elif table_col == 'PRIMARYLOCID':\n",
    "                        mapped_columns.append(table_col)\n",
    "                        mapped_values.append(f\"{primary_id_counter}\")\n",
    "                    elif table_col in column_mapping:\n",
    "                        df_col = column_mapping[table_col]\n",
    "                        if df_col in row:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                    elif table_col not in foreign_key_columns:\n",
    "                        default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                        null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                        blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                        zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                        specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                        if table_col in null_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"NULL\")\n",
    "                        elif table_col in blank_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"' '\")\n",
    "                        elif table_col in zero_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"0\")\n",
    "                        elif table_col in specific_defaults:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                        else:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                if 'AddressID' in mapped_columns:\n",
    "                    address_id_counter += 1\n",
    "                if 'LOCID' in mapped_columns:\n",
    "                    loc_id_counter += 1\n",
    "                if 'PRIMARYLOCID' in mapped_columns:\n",
    "                    primary_id_counter += 1\n",
    "\n",
    "                # Ensure the number of columns matches the number of values\n",
    "                if len(mapped_columns) == len(mapped_values):\n",
    "                    sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                    sql_conn.execute(sql_command)\n",
    "                else:\n",
    "                    print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "# Close the SQL connection after everything is completed\n",
    "sql_conn.close()\n",
    "\n",
    "print(\"Data population completed in Property table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now loccvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import polars as pl\n",
    "\n",
    "# Class to manage SQL connection\n",
    "class SQLConnection:\n",
    "    def __init__(self, server, database):\n",
    "        self.server = server\n",
    "        self.database = database\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def open(self):\n",
    "        # Open a persistent connection\n",
    "        self.connection = pyodbc.connect(\n",
    "            f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "            f\"SERVER={self.server};\"\n",
    "            f\"DATABASE={self.database};\"\n",
    "            \"Trusted_Connection=yes;\"\n",
    "        )\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "    def execute(self, sql_command):\n",
    "        try:\n",
    "            self.cursor.execute(sql_command)\n",
    "            self.connection.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command: {sql_command}\\nException: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.cursor:\n",
    "            self.cursor.close()\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "\n",
    "# Function to get table columns\n",
    "def get_table_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get foreign key columns\n",
    "def get_foreign_key_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"\"\"\n",
    "        SELECT COLUMN_NAME \n",
    "        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE \n",
    "        WHERE TABLE_NAME = '{table_name}' AND CONSTRAINT_NAME IN (\n",
    "            SELECT CONSTRAINT_NAME \n",
    "            FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching foreign key columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Server details\n",
    "server = \"localhost\"\n",
    "\n",
    "table_mappings = {\n",
    "    \"loccvg\": {\"VALUEAMT\":\"Value\",\"LOSSTYPE\":\"losstype\",\"LABELID\":\"labelid\",\"LOCID\":\"LOCNUM\"},\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "# Define behavior for unspecified columns\n",
    "unspecified_column_behavior = {\n",
    "    \"loccvg\": {\n",
    "        \"default\": \"0\",  # General default value for unspecified columns\n",
    "        \"null_columns\": [],  # Columns where value should be NULL\n",
    "        \"blank_columns\": [], # Columns where value should be a blank space\n",
    "        \"zero_columns\": [],  # Columns where value should be 0\n",
    "        \"specific_defaults\":  {\n",
    "        \"ISVALID\": \"1\",\n",
    "        \"PERIL\": perilno,\n",
    "        \"LIMITCUR\": currency,\n",
    "        \"DEDUCTCUR\": currency,\n",
    "        \"VALUECUR\": currency,\n",
    "        \"NONRANKINGDEDUCTCUR\": currency,\n",
    "        \"BIPOI\":12\n",
    "    }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "loccvg_id_counter = 4\n",
    "#loc_id_counter_counter = 4\n",
    "\n",
    "\n",
    "# Assume df and created_databases are defined elsewhere\n",
    "# Split the DataFrame into chunks\n",
    "chunks = [unpivoted_df[i:i + (locations_per_split*3)] for i in range(0, len(unpivoted_df), (locations_per_split*3))]\n",
    "\n",
    "# Open the SQL connection once\n",
    "sql_conn = SQLConnection(server, created_databases[0])\n",
    "sql_conn.open()\n",
    "\n",
    "# Populate each chunk into the corresponding database\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i < len(created_databases):\n",
    "        database = created_databases[i]\n",
    "        print(f\"Populating database: {database}\")\n",
    "\n",
    "        # Switch database if necessary\n",
    "        if sql_conn.database != database:\n",
    "            sql_conn.close()\n",
    "            sql_conn = SQLConnection(server, database)\n",
    "            sql_conn.open()\n",
    "\n",
    "        # Delete existing rows from the Property table\n",
    "        sql_conn.execute(\"DELETE FROM loccvg \")\n",
    "        print(f\"All rows deleted from loccvg table in database {database}.\")\n",
    "\n",
    "        for row in chunk.iter_rows(named=True):\n",
    "            for table_name, column_mapping in table_mappings.items():\n",
    "                all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                mapped_columns = []\n",
    "                mapped_values = []\n",
    "\n",
    "                # Add mapped columns from the DataFrame\n",
    "                for table_col in all_columns:\n",
    "                    if table_col == 'LOCCVGID':\n",
    "                        mapped_columns.append(table_col)\n",
    "                        mapped_values.append(f\"{loccvg_id_counter}\")\n",
    "                    # elif table_col == 'LOCID':\n",
    "                    #     mapped_columns.append(table_col)\n",
    "                    #     mapped_values.append(f\"{loc_id_counter_counter}\")\n",
    "                    \n",
    "                    elif table_col in column_mapping:\n",
    "                        df_col = column_mapping[table_col]\n",
    "                        if df_col in row:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                    elif table_col not in foreign_key_columns:\n",
    "                        default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                        null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                        blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                        zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                        specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                        if table_col in null_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"NULL\")\n",
    "                        elif table_col in blank_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"' '\")\n",
    "                        elif table_col in zero_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"0\")\n",
    "                        elif table_col in specific_defaults:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                        else:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                # Increment the loccvg id counter counters\n",
    "                if 'LOCCVGID' in mapped_columns:\n",
    "                    loccvg_id_counter += 1\n",
    "                # if 'LOCID' in mapped_columns:\n",
    "                #     loc_id_counter_counter += 1\n",
    "                \n",
    "                \n",
    "\n",
    "                # Ensure the number of columns matches the number of values\n",
    "                if len(mapped_columns) == len(mapped_values):\n",
    "                    sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                    sql_conn.execute(sql_command)\n",
    "                else:\n",
    "                    print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "# Close the SQL connection after everything is completed\n",
    "sql_conn.close()\n",
    "\n",
    "print(\"Data population completed in loccvg table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import polars as pl\n",
    "\n",
    "# Class to manage SQL connection\n",
    "class SQLConnection:\n",
    "    def __init__(self, server, database):\n",
    "        self.server = server\n",
    "        self.database = database\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def open(self):\n",
    "        # Open a persistent connection\n",
    "        self.connection = pyodbc.connect(\n",
    "            f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "            f\"SERVER={self.server};\"\n",
    "            f\"DATABASE={self.database};\"\n",
    "            \"Trusted_Connection=yes;\"\n",
    "        )\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "    def execute(self, sql_command):\n",
    "        try:\n",
    "            self.cursor.execute(sql_command)\n",
    "            self.connection.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command: {sql_command}\\nException: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.cursor:\n",
    "            self.cursor.close()\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "\n",
    "# Function to get table columns\n",
    "def get_table_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get foreign key columns\n",
    "def get_foreign_key_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"\"\"\n",
    "        SELECT COLUMN_NAME \n",
    "        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE \n",
    "        WHERE TABLE_NAME = '{table_name}' AND CONSTRAINT_NAME IN (\n",
    "            SELECT CONSTRAINT_NAME \n",
    "            FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching foreign key columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Server details\n",
    "server = \"localhost\"\n",
    "\n",
    "table_mappings = {\n",
    "    \"eqdet\": {\"EQDETID\":\"LOCNUM\",\"LOCID\": \"LOCNUM\"}\n",
    "}\n",
    "\n",
    "# Define behavior for unspecified columns\n",
    "unspecified_column_behavior = {\n",
    "    \"eqdet\": {\n",
    "        \"default\": \"0\",  # General default value for unspecified columns\n",
    "        \"null_columns\": [],  # Columns where value should be NULL\n",
    "        \"blank_columns\": ['MMI_VERSION', \"RMSCLASS\", \"ISOCLASS\", \"ATCCLASS\", \"FIRECLASS\", \"USERCLASS\",\n",
    "                          \"ATCOCC\", \"SICOCC\", \"ISOOCC\", \"IBCOCC\", \"USEROCC\"],  # Columns where value should be a blank space\n",
    "        \"zero_columns\": [],  # Columns where value should be 0\n",
    "        \"specific_defaults\": {  # Columns with specific default values\n",
    "            \"PCNTCOMPLT\": \"100\", \"NONRANKINGSITEDEDCUR\": currency, \"NONRANKINGCOMBINEDDEDCUR\": currency, \"SITEDEDCUR\": currency, \"ISVALID\": \"1\", \"DI\": \"-1\", \"STARTDATE\": undate, \"YEARUPGRAD\": undate, \"YEARSPNKLR\": undate, \"COMPDATE\": undate,\n",
    "            \"COMBINEDLIMCUR\": currency, \"COMBINEDDEDCUR\": currency, \"SITELIMCUR\": currency,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "eqdet_counter = 4\n",
    "loc_id_counter = 4  # Initialize LOCID counter\n",
    "\n",
    "# Assume df and created_databases are defined elsewhere\n",
    "# Split the DataFrame into chunks\n",
    "chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "# Open the SQL connection once\n",
    "sql_conn = SQLConnection(server, created_databases[0])\n",
    "sql_conn.open()\n",
    "\n",
    "# Populate each chunk into the corresponding database\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i < len(created_databases):\n",
    "        database = created_databases[i]\n",
    "        print(f\"Populating database: {database}\")\n",
    "\n",
    "        # Switch database if necessary\n",
    "        if sql_conn.database != database:\n",
    "            sql_conn.close()\n",
    "            sql_conn = SQLConnection(server, database)\n",
    "            sql_conn.open()\n",
    "\n",
    "        # Delete existing rows from the Property table\n",
    "        sql_conn.execute(\"DELETE FROM eqdet \")\n",
    "        print(f\"All rows deleted from eqdet table in database {database}.\")\n",
    "\n",
    "        for row in chunk.iter_rows(named=True):\n",
    "            for table_name, column_mapping in table_mappings.items():\n",
    "                all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                mapped_columns = []\n",
    "                mapped_values = []\n",
    "\n",
    "                # Add mapped columns from the DataFrame\n",
    "                for table_col in all_columns:\n",
    "                    if table_col == 'EQDETID':\n",
    "                        mapped_columns.append(table_col)\n",
    "                        mapped_values.append(f\"{eqdet_counter}\")\n",
    "                    elif table_col == 'LOCID':\n",
    "                        mapped_columns.append(table_col)\n",
    "                        mapped_values.append(f\"{loc_id_counter}\")\n",
    "                    \n",
    "                    elif table_col in column_mapping:\n",
    "                        df_col = column_mapping[table_col]\n",
    "                        if df_col in row:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                    elif table_col not in foreign_key_columns:\n",
    "                        default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                        null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                        blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                        zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                        specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                        if table_col in null_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"NULL\")\n",
    "                        elif table_col in blank_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"' '\")\n",
    "                        elif table_col in zero_columns:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(\"0\")\n",
    "                        elif table_col in specific_defaults:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                        else:\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                if 'EQDETID' in mapped_columns:\n",
    "                    eqdet_counter += 1\n",
    "                if 'LOCID' in mapped_columns:\n",
    "                    loc_id_counter += 1\n",
    "                \n",
    "\n",
    "                # Ensure the number of columns matches the number of values\n",
    "                if len(mapped_columns) == len(mapped_values):\n",
    "                    sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                    sql_conn.execute(sql_command)\n",
    "                else:\n",
    "                    print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "# Close the SQL connection after everything is completed\n",
    "sql_conn.close()\n",
    "\n",
    "print(\"Data population completed in eqdet table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import polars as pl\n",
    "\n",
    "# Class to manage SQL connection\n",
    "class SQLConnection:\n",
    "    def __init__(self, server, database):\n",
    "        self.server = server\n",
    "        self.database = database\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def open(self):\n",
    "        # Open a persistent connection\n",
    "        self.connection = pyodbc.connect(\n",
    "            f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "            f\"SERVER={self.server};\"\n",
    "            f\"DATABASE={self.database};\"\n",
    "            \"Trusted_Connection=yes;\"\n",
    "        )\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "    def execute(self, sql_command):\n",
    "        try:\n",
    "            self.cursor.execute(sql_command)\n",
    "            self.connection.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command: {sql_command}\\nException: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.cursor:\n",
    "            self.cursor.close()\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "\n",
    "# Function to get table columns\n",
    "def get_table_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to get foreign key columns\n",
    "def get_foreign_key_columns(cursor, table_name):\n",
    "    try:\n",
    "        sql_command = f\"\"\"\n",
    "        SELECT COLUMN_NAME \n",
    "        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE \n",
    "        WHERE TABLE_NAME = '{table_name}' AND CONSTRAINT_NAME IN (\n",
    "            SELECT CONSTRAINT_NAME \n",
    "            FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "        return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching foreign key columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Server details\n",
    "server = \"localhost\"\n",
    "\n",
    "\n",
    "\n",
    "if perilno==1:\n",
    "\n",
    "    table_mappings = {\n",
    "        \"eqdet\": {\"EQDETID\":\"LOCNUM\",\"LOCID\": \"LOCNUM\"}\n",
    "    }\n",
    "\n",
    "    # Define behavior for unspecified columns\n",
    "    unspecified_column_behavior = {\n",
    "        \"eqdet\": {\n",
    "            \"default\": \"0\",  # General default value for unspecified columns\n",
    "            \"null_columns\": [],  # Columns where value should be NULL\n",
    "            \"blank_columns\": ['MMI_VERSION', \"RMSCLASS\", \"ISOCLASS\", \"ATCCLASS\", \"FIRECLASS\", \"USERCLASS\",\n",
    "                            \"ATCOCC\", \"SICOCC\", \"ISOOCC\", \"IBCOCC\", \"USEROCC\"],  # Columns where value should be a blank space\n",
    "            \"zero_columns\": [],  # Columns where value should be 0\n",
    "            \"specific_defaults\": {  # Columns with specific default values\n",
    "                \"PCNTCOMPLT\": \"100\", \"NONRANKINGSITEDEDCUR\": currency, \"NONRANKINGCOMBINEDDEDCUR\": currency, \"SITEDEDCUR\": currency, \"ISVALID\": \"1\", \"DI\": \"-1\", \"STARTDATE\": undate, \"YEARUPGRAD\": undate, \"YEARSPNKLR\": undate, \"COMPDATE\": undate,\n",
    "                \"COMBINEDLIMCUR\": currency, \"COMBINEDDEDCUR\": currency, \"SITELIMCUR\": currency,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "    eqdet_counter = 4\n",
    "    loc_id_counter = 4  # Initialize LOCID counter\n",
    "\n",
    "    # Assume df and created_databases are defined elsewhere\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "    # Open the SQL connection once\n",
    "    sql_conn = SQLConnection(server, created_databases[0])\n",
    "    sql_conn.open()\n",
    "\n",
    "    # Populate each chunk into the corresponding database\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i < len(created_databases):\n",
    "            database = created_databases[i]\n",
    "            print(f\"Populating database: {database}\")\n",
    "\n",
    "            # Switch database if necessary\n",
    "            if sql_conn.database != database:\n",
    "                sql_conn.close()\n",
    "                sql_conn = SQLConnection(server, database)\n",
    "                sql_conn.open()\n",
    "\n",
    "            # Delete existing rows from the Property table\n",
    "            sql_conn.execute(\"DELETE FROM eqdet \")\n",
    "            print(f\"All rows deleted from eqdet table in database {database}.\")\n",
    "\n",
    "            for row in chunk.iter_rows(named=True):\n",
    "                for table_name, column_mapping in table_mappings.items():\n",
    "                    all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                    foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                    mapped_columns = []\n",
    "                    mapped_values = []\n",
    "\n",
    "                    # Add mapped columns from the DataFrame\n",
    "                    for table_col in all_columns:\n",
    "                        if table_col == 'EQDETID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{eqdet_counter}\")\n",
    "                        elif table_col == 'LOCID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{loc_id_counter}\")\n",
    "                        \n",
    "                        elif table_col in column_mapping:\n",
    "                            df_col = column_mapping[table_col]\n",
    "                            if df_col in row:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                        elif table_col not in foreign_key_columns:\n",
    "                            default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                            null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                            blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                            zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                            specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                            if table_col in null_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"NULL\")\n",
    "                            elif table_col in blank_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"' '\")\n",
    "                            elif table_col in zero_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"0\")\n",
    "                            elif table_col in specific_defaults:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                            else:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                    # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                    if 'EQDETID' in mapped_columns:\n",
    "                        eqdet_counter += 1\n",
    "                    if 'LOCID' in mapped_columns:\n",
    "                        loc_id_counter += 1\n",
    "                    \n",
    "\n",
    "                    # Ensure the number of columns matches the number of values\n",
    "                    if len(mapped_columns) == len(mapped_values):\n",
    "                        sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                        sql_conn.execute(sql_command)\n",
    "                    else:\n",
    "                        print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "    # Close the SQL connection after everything is completed\n",
    "    sql_conn.close()\n",
    "\n",
    "    print(\"Data population completed in eqdet table.\")\n",
    "\n",
    "elif perilno==2:\n",
    "\n",
    "    table_mappings = {\n",
    "        \"hudet\": {\"HUDETID\":\"LOCNUM\",\"LOCID\": \"LOCNUM\"}\n",
    "    }\n",
    "\n",
    "    # Define behavior for unspecified columns\n",
    "    unspecified_column_behavior = {\n",
    "        \"hudet\": {\n",
    "            \"default\": \"0\",  # General default value for unspecified columns\n",
    "            \"null_columns\": [],  # Columns where value should be NULL\n",
    "            \"blank_columns\": ['MMI_VERSION', \"RMSCLASS\", \"ISOCLASS\", \"ATCCLASS\", \"FIRECLASS\", \"USERCLASS\",\n",
    "                            \"ATCOCC\", \"SICOCC\", \"ISOOCC\", \"IBCOCC\", \"USEROCC\"],  # Columns where value should be a blank space\n",
    "            \"zero_columns\": [],  # Columns where value should be 0\n",
    "            \"specific_defaults\": {  # Columns with specific default values\n",
    "                \"PCNTCOMPLT\": \"100\", \"NONRANKINGSITEDEDCUR\": currency, \"NONRANKINGCOMBINEDDEDCUR\": currency, \"SITEDEDCUR\": currency, \"ISVALID\": \"1\", \"DI\": \"-1\", \"STARTDATE\": undate, \"YEARUPGRAD\": undate, \"YEARSPNKLR\": undate, \"COMPDATE\": undate,\n",
    "                \"COMBINEDLIMCUR\": currency, \"COMBINEDDEDCUR\": currency, \"SITELIMCUR\": currency,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "    eqdet_counter = 4\n",
    "    loc_id_counter = 4  # Initialize LOCID counter\n",
    "\n",
    "    # Assume df and created_databases are defined elsewhere\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "    # Open the SQL connection once\n",
    "    sql_conn = SQLConnection(server, created_databases[0])\n",
    "    sql_conn.open()\n",
    "\n",
    "    # Populate each chunk into the corresponding database\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i < len(created_databases):\n",
    "            database = created_databases[i]\n",
    "            print(f\"Populating database: {database}\")\n",
    "\n",
    "            # Switch database if necessary\n",
    "            if sql_conn.database != database:\n",
    "                sql_conn.close()\n",
    "                sql_conn = SQLConnection(server, database)\n",
    "                sql_conn.open()\n",
    "\n",
    "            # Delete existing rows from the Property table\n",
    "            sql_conn.execute(\"DELETE FROM eqdet \")\n",
    "            print(f\"All rows deleted from eqdet table in database {database}.\")\n",
    "\n",
    "            for row in chunk.iter_rows(named=True):\n",
    "                for table_name, column_mapping in table_mappings.items():\n",
    "                    all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                    foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                    mapped_columns = []\n",
    "                    mapped_values = []\n",
    "\n",
    "                    # Add mapped columns from the DataFrame\n",
    "                    for table_col in all_columns:\n",
    "                        if table_col == 'EQDETID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{eqdet_counter}\")\n",
    "                        elif table_col == 'LOCID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{loc_id_counter}\")\n",
    "                        \n",
    "                        elif table_col in column_mapping:\n",
    "                            df_col = column_mapping[table_col]\n",
    "                            if df_col in row:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                        elif table_col not in foreign_key_columns:\n",
    "                            default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                            null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                            blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                            zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                            specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                            if table_col in null_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"NULL\")\n",
    "                            elif table_col in blank_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"' '\")\n",
    "                            elif table_col in zero_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"0\")\n",
    "                            elif table_col in specific_defaults:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                            else:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                    # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                    if 'EQDETID' in mapped_columns:\n",
    "                        eqdet_counter += 1\n",
    "                    if 'LOCID' in mapped_columns:\n",
    "                        loc_id_counter += 1\n",
    "                    \n",
    "\n",
    "                    # Ensure the number of columns matches the number of values\n",
    "                    if len(mapped_columns) == len(mapped_values):\n",
    "                        sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                        sql_conn.execute(sql_command)\n",
    "                    else:\n",
    "                        print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "    # Close the SQL connection after everything is completed\n",
    "    sql_conn.close()\n",
    "\n",
    "    print(\"Data population completed in eqdet table.\")\n",
    "\n",
    "elif perilno==3:\n",
    "\n",
    "    table_mappings = {\n",
    "        \"eqdet\": {\"EQDETID\":\"LOCNUM\",\"LOCID\": \"LOCNUM\"}\n",
    "    }\n",
    "\n",
    "    # Define behavior for unspecified columns\n",
    "    unspecified_column_behavior = {\n",
    "        \"eqdet\": {\n",
    "            \"default\": \"0\",  # General default value for unspecified columns\n",
    "            \"null_columns\": [],  # Columns where value should be NULL\n",
    "            \"blank_columns\": ['MMI_VERSION', \"RMSCLASS\", \"ISOCLASS\", \"ATCCLASS\", \"FIRECLASS\", \"USERCLASS\",\n",
    "                            \"ATCOCC\", \"SICOCC\", \"ISOOCC\", \"IBCOCC\", \"USEROCC\"],  # Columns where value should be a blank space\n",
    "            \"zero_columns\": [],  # Columns where value should be 0\n",
    "            \"specific_defaults\": {  # Columns with specific default values\n",
    "                \"PCNTCOMPLT\": \"100\", \"NONRANKINGSITEDEDCUR\": currency, \"NONRANKINGCOMBINEDDEDCUR\": currency, \"SITEDEDCUR\": currency, \"ISVALID\": \"1\", \"DI\": \"-1\", \"STARTDATE\": undate, \"YEARUPGRAD\": undate, \"YEARSPNKLR\": undate, \"COMPDATE\": undate,\n",
    "                \"COMBINEDLIMCUR\": currency, \"COMBINEDDEDCUR\": currency, \"SITELIMCUR\": currency,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "    eqdet_counter = 4\n",
    "    loc_id_counter = 4  # Initialize LOCID counter\n",
    "\n",
    "    # Assume df and created_databases are defined elsewhere\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "    # Open the SQL connection once\n",
    "    sql_conn = SQLConnection(server, created_databases[0])\n",
    "    sql_conn.open()\n",
    "\n",
    "    # Populate each chunk into the corresponding database\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i < len(created_databases):\n",
    "            database = created_databases[i]\n",
    "            print(f\"Populating database: {database}\")\n",
    "\n",
    "            # Switch database if necessary\n",
    "            if sql_conn.database != database:\n",
    "                sql_conn.close()\n",
    "                sql_conn = SQLConnection(server, database)\n",
    "                sql_conn.open()\n",
    "\n",
    "            # Delete existing rows from the Property table\n",
    "            sql_conn.execute(\"DELETE FROM eqdet \")\n",
    "            print(f\"All rows deleted from eqdet table in database {database}.\")\n",
    "\n",
    "            for row in chunk.iter_rows(named=True):\n",
    "                for table_name, column_mapping in table_mappings.items():\n",
    "                    all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                    foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                    mapped_columns = []\n",
    "                    mapped_values = []\n",
    "\n",
    "                    # Add mapped columns from the DataFrame\n",
    "                    for table_col in all_columns:\n",
    "                        if table_col == 'EQDETID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{eqdet_counter}\")\n",
    "                        elif table_col == 'LOCID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{loc_id_counter}\")\n",
    "                        \n",
    "                        elif table_col in column_mapping:\n",
    "                            df_col = column_mapping[table_col]\n",
    "                            if df_col in row:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                        elif table_col not in foreign_key_columns:\n",
    "                            default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                            null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                            blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                            zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                            specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                            if table_col in null_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"NULL\")\n",
    "                            elif table_col in blank_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"' '\")\n",
    "                            elif table_col in zero_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"0\")\n",
    "                            elif table_col in specific_defaults:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                            else:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                    # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                    if 'EQDETID' in mapped_columns:\n",
    "                        eqdet_counter += 1\n",
    "                    if 'LOCID' in mapped_columns:\n",
    "                        loc_id_counter += 1\n",
    "                    \n",
    "\n",
    "                    # Ensure the number of columns matches the number of values\n",
    "                    if len(mapped_columns) == len(mapped_values):\n",
    "                        sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                        sql_conn.execute(sql_command)\n",
    "                    else:\n",
    "                        print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "    # Close the SQL connection after everything is completed\n",
    "    sql_conn.close()\n",
    "\n",
    "    print(\"Data population completed in eqdet table.\")\n",
    "elif perilno==4:\n",
    "\n",
    "    table_mappings = {\n",
    "        \"eqdet\": {\"EQDETID\":\"LOCNUM\",\"LOCID\": \"LOCNUM\"}\n",
    "    }\n",
    "\n",
    "    # Define behavior for unspecified columns\n",
    "    unspecified_column_behavior = {\n",
    "        \"eqdet\": {\n",
    "            \"default\": \"0\",  # General default value for unspecified columns\n",
    "            \"null_columns\": [],  # Columns where value should be NULL\n",
    "            \"blank_columns\": ['MMI_VERSION', \"RMSCLASS\", \"ISOCLASS\", \"ATCCLASS\", \"FIRECLASS\", \"USERCLASS\",\n",
    "                            \"ATCOCC\", \"SICOCC\", \"ISOOCC\", \"IBCOCC\", \"USEROCC\"],  # Columns where value should be a blank space\n",
    "            \"zero_columns\": [],  # Columns where value should be 0\n",
    "            \"specific_defaults\": {  # Columns with specific default values\n",
    "                \"PCNTCOMPLT\": \"100\", \"NONRANKINGSITEDEDCUR\": currency, \"NONRANKINGCOMBINEDDEDCUR\": currency, \"SITEDEDCUR\": currency, \"ISVALID\": \"1\", \"DI\": \"-1\", \"STARTDATE\": undate, \"YEARUPGRAD\": undate, \"YEARSPNKLR\": undate, \"COMPDATE\": undate,\n",
    "                \"COMBINEDLIMCUR\": currency, \"COMBINEDDEDCUR\": currency, \"SITELIMCUR\": currency,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "    eqdet_counter = 4\n",
    "    loc_id_counter = 4  # Initialize LOCID counter\n",
    "\n",
    "    # Assume df and created_databases are defined elsewhere\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "    # Open the SQL connection once\n",
    "    sql_conn = SQLConnection(server, created_databases[0])\n",
    "    sql_conn.open()\n",
    "\n",
    "    # Populate each chunk into the corresponding database\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i < len(created_databases):\n",
    "            database = created_databases[i]\n",
    "            print(f\"Populating database: {database}\")\n",
    "\n",
    "            # Switch database if necessary\n",
    "            if sql_conn.database != database:\n",
    "                sql_conn.close()\n",
    "                sql_conn = SQLConnection(server, database)\n",
    "                sql_conn.open()\n",
    "\n",
    "            # Delete existing rows from the Property table\n",
    "            sql_conn.execute(\"DELETE FROM eqdet \")\n",
    "            print(f\"All rows deleted from eqdet table in database {database}.\")\n",
    "\n",
    "            for row in chunk.iter_rows(named=True):\n",
    "                for table_name, column_mapping in table_mappings.items():\n",
    "                    all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                    foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                    mapped_columns = []\n",
    "                    mapped_values = []\n",
    "\n",
    "                    # Add mapped columns from the DataFrame\n",
    "                    for table_col in all_columns:\n",
    "                        if table_col == 'EQDETID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{eqdet_counter}\")\n",
    "                        elif table_col == 'LOCID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{loc_id_counter}\")\n",
    "                        \n",
    "                        elif table_col in column_mapping:\n",
    "                            df_col = column_mapping[table_col]\n",
    "                            if df_col in row:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                        elif table_col not in foreign_key_columns:\n",
    "                            default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                            null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                            blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                            zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                            specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                            if table_col in null_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"NULL\")\n",
    "                            elif table_col in blank_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"' '\")\n",
    "                            elif table_col in zero_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"0\")\n",
    "                            elif table_col in specific_defaults:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                            else:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                    # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                    if 'EQDETID' in mapped_columns:\n",
    "                        eqdet_counter += 1\n",
    "                    if 'LOCID' in mapped_columns:\n",
    "                        loc_id_counter += 1\n",
    "                    \n",
    "\n",
    "                    # Ensure the number of columns matches the number of values\n",
    "                    if len(mapped_columns) == len(mapped_values):\n",
    "                        sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                        sql_conn.execute(sql_command)\n",
    "                    else:\n",
    "                        print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "    # Close the SQL connection after everything is completed\n",
    "    sql_conn.close()\n",
    "\n",
    "    print(\"Data population completed in eqdet table.\")\n",
    "elif perilno==5:\n",
    "\n",
    "    table_mappings = {\n",
    "        \"eqdet\": {\"EQDETID\":\"LOCNUM\",\"LOCID\": \"LOCNUM\"}\n",
    "    }\n",
    "\n",
    "    # Define behavior for unspecified columns\n",
    "    unspecified_column_behavior = {\n",
    "        \"eqdet\": {\n",
    "            \"default\": \"0\",  # General default value for unspecified columns\n",
    "            \"null_columns\": [],  # Columns where value should be NULL\n",
    "            \"blank_columns\": ['MMI_VERSION', \"RMSCLASS\", \"ISOCLASS\", \"ATCCLASS\", \"FIRECLASS\", \"USERCLASS\",\n",
    "                            \"ATCOCC\", \"SICOCC\", \"ISOOCC\", \"IBCOCC\", \"USEROCC\"],  # Columns where value should be a blank space\n",
    "            \"zero_columns\": [],  # Columns where value should be 0\n",
    "            \"specific_defaults\": {  # Columns with specific default values\n",
    "                \"PCNTCOMPLT\": \"100\", \"NONRANKINGSITEDEDCUR\": currency, \"NONRANKINGCOMBINEDDEDCUR\": currency, \"SITEDEDCUR\": currency, \"ISVALID\": \"1\", \"DI\": \"-1\", \"STARTDATE\": undate, \"YEARUPGRAD\": undate, \"YEARSPNKLR\": undate, \"COMPDATE\": undate,\n",
    "                \"COMBINEDLIMCUR\": currency, \"COMBINEDDEDCUR\": currency, \"SITELIMCUR\": currency,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "    eqdet_counter = 4\n",
    "    loc_id_counter = 4  # Initialize LOCID counter\n",
    "\n",
    "    # Assume df and created_databases are defined elsewhere\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "    # Open the SQL connection once\n",
    "    sql_conn = SQLConnection(server, created_databases[0])\n",
    "    sql_conn.open()\n",
    "\n",
    "    # Populate each chunk into the corresponding database\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i < len(created_databases):\n",
    "            database = created_databases[i]\n",
    "            print(f\"Populating database: {database}\")\n",
    "\n",
    "            # Switch database if necessary\n",
    "            if sql_conn.database != database:\n",
    "                sql_conn.close()\n",
    "                sql_conn = SQLConnection(server, database)\n",
    "                sql_conn.open()\n",
    "\n",
    "            # Delete existing rows from the Property table\n",
    "            sql_conn.execute(\"DELETE FROM eqdet \")\n",
    "            print(f\"All rows deleted from eqdet table in database {database}.\")\n",
    "\n",
    "            for row in chunk.iter_rows(named=True):\n",
    "                for table_name, column_mapping in table_mappings.items():\n",
    "                    all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                    foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                    mapped_columns = []\n",
    "                    mapped_values = []\n",
    "\n",
    "                    # Add mapped columns from the DataFrame\n",
    "                    for table_col in all_columns:\n",
    "                        if table_col == 'EQDETID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{eqdet_counter}\")\n",
    "                        elif table_col == 'LOCID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{loc_id_counter}\")\n",
    "                        \n",
    "                        elif table_col in column_mapping:\n",
    "                            df_col = column_mapping[table_col]\n",
    "                            if df_col in row:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                        elif table_col not in foreign_key_columns:\n",
    "                            default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                            null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                            blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                            zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                            specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                            if table_col in null_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"NULL\")\n",
    "                            elif table_col in blank_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"' '\")\n",
    "                            elif table_col in zero_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"0\")\n",
    "                            elif table_col in specific_defaults:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                            else:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                    # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                    if 'EQDETID' in mapped_columns:\n",
    "                        eqdet_counter += 1\n",
    "                    if 'LOCID' in mapped_columns:\n",
    "                        loc_id_counter += 1\n",
    "                    \n",
    "\n",
    "                    # Ensure the number of columns matches the number of values\n",
    "                    if len(mapped_columns) == len(mapped_values):\n",
    "                        sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                        sql_conn.execute(sql_command)\n",
    "                    else:\n",
    "                        print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "    # Close the SQL connection after everything is completed\n",
    "    sql_conn.close()\n",
    "\n",
    "    print(\"Data population completed in eqdet table.\")\n",
    "elif perilno==6:\n",
    "\n",
    "    table_mappings = {\n",
    "        \"eqdet\": {\"EQDETID\":\"LOCNUM\",\"LOCID\": \"LOCNUM\"}\n",
    "    }\n",
    "\n",
    "    # Define behavior for unspecified columns\n",
    "    unspecified_column_behavior = {\n",
    "        \"eqdet\": {\n",
    "            \"default\": \"0\",  # General default value for unspecified columns\n",
    "            \"null_columns\": [],  # Columns where value should be NULL\n",
    "            \"blank_columns\": ['MMI_VERSION', \"RMSCLASS\", \"ISOCLASS\", \"ATCCLASS\", \"FIRECLASS\", \"USERCLASS\",\n",
    "                            \"ATCOCC\", \"SICOCC\", \"ISOOCC\", \"IBCOCC\", \"USEROCC\"],  # Columns where value should be a blank space\n",
    "            \"zero_columns\": [],  # Columns where value should be 0\n",
    "            \"specific_defaults\": {  # Columns with specific default values\n",
    "                \"PCNTCOMPLT\": \"100\", \"NONRANKINGSITEDEDCUR\": currency, \"NONRANKINGCOMBINEDDEDCUR\": currency, \"SITEDEDCUR\": currency, \"ISVALID\": \"1\", \"DI\": \"-1\", \"STARTDATE\": undate, \"YEARUPGRAD\": undate, \"YEARSPNKLR\": undate, \"COMPDATE\": undate,\n",
    "                \"COMBINEDLIMCUR\": currency, \"COMBINEDDEDCUR\": currency, \"SITELIMCUR\": currency,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Counter for AddressID, LOCID, and PRIMARYLOCID\n",
    "    eqdet_counter = 4\n",
    "    loc_id_counter = 4  # Initialize LOCID counter\n",
    "\n",
    "    # Assume df and created_databases are defined elsewhere\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df[i:i + locations_per_split] for i in range(0, len(df), locations_per_split)]\n",
    "\n",
    "    # Open the SQL connection once\n",
    "    sql_conn = SQLConnection(server, created_databases[0])\n",
    "    sql_conn.open()\n",
    "\n",
    "    # Populate each chunk into the corresponding database\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i < len(created_databases):\n",
    "            database = created_databases[i]\n",
    "            print(f\"Populating database: {database}\")\n",
    "\n",
    "            # Switch database if necessary\n",
    "            if sql_conn.database != database:\n",
    "                sql_conn.close()\n",
    "                sql_conn = SQLConnection(server, database)\n",
    "                sql_conn.open()\n",
    "\n",
    "            # Delete existing rows from the Property table\n",
    "            sql_conn.execute(\"DELETE FROM eqdet \")\n",
    "            print(f\"All rows deleted from eqdet table in database {database}.\")\n",
    "\n",
    "            for row in chunk.iter_rows(named=True):\n",
    "                for table_name, column_mapping in table_mappings.items():\n",
    "                    all_columns = get_table_columns(sql_conn.cursor, table_name)\n",
    "                    foreign_key_columns = get_foreign_key_columns(sql_conn.cursor, table_name)\n",
    "\n",
    "                    mapped_columns = []\n",
    "                    mapped_values = []\n",
    "\n",
    "                    # Add mapped columns from the DataFrame\n",
    "                    for table_col in all_columns:\n",
    "                        if table_col == 'EQDETID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{eqdet_counter}\")\n",
    "                        elif table_col == 'LOCID':\n",
    "                            mapped_columns.append(table_col)\n",
    "                            mapped_values.append(f\"{loc_id_counter}\")\n",
    "                        \n",
    "                        elif table_col in column_mapping:\n",
    "                            df_col = column_mapping[table_col]\n",
    "                            if df_col in row:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{row[df_col]}'\")\n",
    "                        elif table_col not in foreign_key_columns:\n",
    "                            default_behavior = unspecified_column_behavior.get(table_name, {\"default\": \"0\"})\n",
    "                            null_columns = default_behavior.get(\"null_columns\", [])\n",
    "                            blank_columns = default_behavior.get(\"blank_columns\", [])\n",
    "                            zero_columns = default_behavior.get(\"zero_columns\", [])\n",
    "                            specific_defaults = default_behavior.get(\"specific_defaults\", {})\n",
    "\n",
    "                            if table_col in null_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"NULL\")\n",
    "                            elif table_col in blank_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"' '\")\n",
    "                            elif table_col in zero_columns:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(\"0\")\n",
    "                            elif table_col in specific_defaults:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(f\"'{specific_defaults[table_col]}'\")\n",
    "                            else:\n",
    "                                mapped_columns.append(table_col)\n",
    "                                mapped_values.append(default_behavior.get(\"default\", \"0\"))\n",
    "\n",
    "                    # Increment the AddressID, LOCID, and PRIMARYLOCID counters\n",
    "                    if 'EQDETID' in mapped_columns:\n",
    "                        eqdet_counter += 1\n",
    "                    if 'LOCID' in mapped_columns:\n",
    "                        loc_id_counter += 1\n",
    "                    \n",
    "\n",
    "                    # Ensure the number of columns matches the number of values\n",
    "                    if len(mapped_columns) == len(mapped_values):\n",
    "                        sql_command = f\"INSERT INTO {table_name} ({', '.join(mapped_columns)}) VALUES ({', '.join(mapped_values)})\"\n",
    "                        sql_conn.execute(sql_command)\n",
    "                    else:\n",
    "                        print(\"Mismatch in columns and values, skipping row.\")\n",
    "\n",
    "    # Close the SQL connection after everything is completed\n",
    "    sql_conn.close()\n",
    "\n",
    "    print(\"Data population completed in eqdet table.\")\n",
    "else:\n",
    "    PRINT(\"PERIL NOT VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
